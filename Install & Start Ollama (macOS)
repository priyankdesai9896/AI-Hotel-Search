1. Install & Start Ollama (macOS)

* Download & install
* Go to https://ollama.com/download
* Download the macOS .dmg installer
* Drag Ollama.app to your Applications folder

2. Start Ollama server

* Launch Ollama.app from Applications (it runs a background server at http://localhost:11434)
* You should see a little Ollama icon in your menu bar (top-right)

3. Pull and run a model

In your terminal run the following commands:

ollama pull llama3
ollama run llama3

* The first pull will download a few GB, so it may take time.
* Once running, you should see a REPL where you can type prompts.

4. Verify server is running

Test with following command:

curl http://localhost:11434/api/tags

If it lists available models (e.g. llama3), the server is good to go.
